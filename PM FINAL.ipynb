{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48a62511-df57-4aa8-931e-113cdc38121a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing s&p tickers:  12%|███████                                                  | 62/502 [00:33<04:49,  1.52it/s]$BRK.B: possibly delisted; no timezone found\n",
      "processing s&p tickers:  15%|████████▋                                                | 77/502 [00:40<03:55,  1.80it/s]$BF.B: possibly delisted; no price data found  (1d 1925-10-31 -> 2024-10-06)\n",
      "processing s&p tickers: 100%|████████████████████████████████████████████████████████| 502/502 [04:15<00:00,  1.97it/s]\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from scipy.stats import t\n",
    "from scipy import stats\n",
    "import xml.etree.ElementTree as ET\n",
    "import requests\n",
    "\n",
    "#Optional status bars\n",
    "from tqdm import tqdm\n",
    "\n",
    "def calculate_mean_dividend_growth(div):\n",
    "    year_div = div.resample('Y').sum()\n",
    "    div_pct = year_div.pct_change()\n",
    "    filter_div_pct = div_pct[(div_pct <= 1.0) & (div_pct >= -1.0)]\n",
    "    return filter_div_pct.mean() if len(filter_div_pct) > 0 else 0\n",
    "\n",
    "#Pull data from the treasury on the current 10-year treasury rate\n",
    "fed_scrape ='https://home.treasury.gov/sites/default/files/interest-rates/yield.xml'\n",
    "response = requests.get(fed_scrape)  #we want to bootstrap\n",
    "if response.status_code == 200:\n",
    "    treas_xml = response.content\n",
    "    root = ET.fromstring(treas_xml)\n",
    "    subchildren = root.findall('.//AVERAGE_10YEAR')\n",
    "    if subchildren:\n",
    "        latest_subchild = subchildren[-1]\n",
    "    else:\n",
    "        print('unable to locate published average.')\n",
    "        subchildren_1 = root.findall('.//BC_10YEAR')\n",
    "        if subchildren_1:\n",
    "            lastest_subchild = subchildren[-1]\n",
    "        else:\n",
    "            print('unable to find published data')\n",
    "            latest_subchild = str(input('Enter manually'))\n",
    "else:\n",
    "    print(f\"failed to retrieve treasury data. Status code: {response.status_code}\")\n",
    "\n",
    "rf = float(latest_subchild.text)/100\n",
    "\n",
    "#Get an implied ERP estimate using the dividend growth model \n",
    "sp500 = \"MMM,AOS,ABT,ABBV,ACN,ADBE,AMD,AES,AFL,A,APD,ABNB,AKAM,ALB,ARE,ALGN,ALLE,LNT,ALL,GOOGL,GOOG,MO,AMZN,AMCR,AEE,AAL,AEP,AXP,AIG,AMT,AWK,AMP,AME,AMGN,APH,ADI,ANSS,AON,APA,AAPL,AMAT,APTV,ACGL,ADM,ANET,AJG,AIZ,T,ATO,ADSK,ADP,AZO,AVB,AVY,AXON,BKR,BALL,BAC,BK,BBWI,BAX,BDX,BRK.B,BBY,BIO,TECH,BIIB,BLK,BX,BA,BKNG,BWA,BSX,BMY,AVGO,BR,BRO,BF.B,BLDR,BG,BXP,CDNS,CZR,CPT,CPB,COF,CAH,KMX,CCL,CARR,CTLT,CAT,CBOE,CBRE,CDW,CE,COR,CNC,CNP,CF,CHRW,CRL,SCHW,CHTR,CVX,CMG,CB,CHD,CI,CINF,CTAS,CSCO,C,CFG,CLX,CME,CMS,KO,CTSH,CL,CMCSA,CAG,COP,ED,STZ,CEG,COO,CPRT,GLW,CPAY,CTVA,CSGP,COST,CTRA,CRWD,CCI,CSX,CMI,CVS,DHR,DRI,DVA,DAY,DECK,DE,DAL,DVN,DXCM,FANG,DLR,DFS,DG,DLTR,D,DPZ,DOV,DOW,DHI,DTE,DUK,DD,EMN,ETN,EBAY,ECL,EIX,EW,EA,ELV,EMR,ENPH,ETR,EOG,EPAM,EQT,EFX,EQIX,EQR,ESS,EL,ETSY,EG,EVRG,ES,EXC,EXPE,EXPD,EXR,XOM,FFIV,FDS,FICO,FAST,FRT,FDX,FIS,FITB,FSLR,FE,FI,FMC,F,FTNT,FTV,FOXA,FOX,BEN,FCX,GRMN,IT,GE,GEHC,GEV,GEN,GNRC,GD,GIS,GM,GPC,GILD,GPN,GL,GDDY,GS,HAL,HIG,HAS,HCA,DOC,HSIC,HSY,HES,HPE,HLT,HOLX,HD,HON,HRL,HST,HWM,HPQ,HUBB,HUM,HBAN,HII,IBM,IEX,IDXX,ITW,INCY,IR,PODD,INTC,ICE,IFF,IP,IPG,INTU,ISRG,IVZ,INVH,IQV,IRM,JBHT,JBL,JKHY,J,JNJ,JCI,JPM,JNPR,K,KVUE,KDP,KEY,KEYS,KMB,KIM,KMI,KKR,KLAC,KHC,KR,LHX,LH,LRCX,LW,LVS,LDOS,LEN,LLY,LIN,LYV,LKQ,LMT,L,LOW,LULU,LYB,MTB,MRO,MPC,MKTX,MAR,MMC,MLM,MAS,MA,MTCH,MKC,MCD,MCK,MDT,MRK,META,MET,MTD,MGM,MCHP,MU,MSFT,MAA,MRNA,MHK,MOH,TAP,MPWR,MNST,MCO,MS,MOS,MSI,MSCI,NDAQ,NTAP,NFLX,NEM,NWSA,NWS,NEE,NKE,NI,NDSN,NSC,NTRS,NOC,NCLH,NRG,NUE,NVDA,NVR,NXPI,ORLY,OXY,ODFL,OMC,ON,OKE,ORCL,OTIS,PCAR,PKG,PANW,PARA,PH,PAYX,PAYC,PYPL,PNR,PEP,PFE,PCG,PM,PSX,PNW,PNC,POOL,PPG,PPL,PFG,PG,PGR,PLD,PRU,PEG,PTC,PSA,PHM,QRVO,PWR,QCOM,DGX,RL,RJF,RTX,O,REG,REGN,RF,RSG,RMD,RVTY,ROK,ROL,ROP,ROST,RCL,SPGI,CRM,SBAC,SLB,STX,SRE,NOW,SHW,SPG,SWKS,SJM,SW,SNA,SOLV,SO,LUV,SWK,SBUX,STT,STLD,STE,SYK,SMCI,SYF,SNPS,SYY,TMUS,TROW,TTWO,TPR,TRGP,TGT,TEL,TDY,TFX,TER,TSLA,TXN,TXT,TMO,TJX,TSCO,TT,TDG,TRV,TRMB,TFC,TYL,TSN,USB,UBER,UDR,ULTA,UNP,UAL,UPS,URI,UNH,UHS,VLO,VTR,VLTO,VRSN,VRSK,VZ,VRTX,VTRS,VICI,V,VST,VMC,WRB,GWW,WAB,WBA,WMT,DIS,WBD,WM,WAT,WEC,WFC,WELL,WST,WDC,WY,WMB,WTW,WYNN,XEL,XYL,YUM,ZBRA,ZBH,ZTS\"\n",
    "sp500_tickers =sp500.split(',')\n",
    "idx_dict = {}\n",
    "\n",
    "#Uses the defined function to collect dividend data \n",
    "for tick in tqdm(sp500_tickers, desc=\"processing s&p tickers\"):\n",
    "    stock =yf.Ticker(tick)\n",
    "    div=stock.dividends\n",
    "    if not div.empty:\n",
    "        mean_div_growth = calculate_mean_dividend_growth(div)\n",
    "        idx_dict[tick] = mean_div_growth\n",
    "    else:\n",
    "        idx_dict[tick] = 0\n",
    "        \n",
    "#average growth on the collected series, then DGM\n",
    "idx_div_df = pd.Series(idx_dict)\n",
    "growth = idx_div_df.mean()\n",
    "div_forward = (1 + growth) * idx_div_df.iloc[-1]\n",
    "idx_quote = yf.Ticker('^GSPC').history(period='1d')['Close'].iloc[-1]\n",
    "implied_erp = ((div_forward / idx_quote) + growth) - rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f6a7a71-635f-4b86-90d8-097aae5dc7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Type in Tickers to be Analyzed. Type 'DONE' when done. MSFt\n",
      "Type in Tickers to be Analyzed. Type 'DONE' when done. DONE\n",
      "Enter beginning date of search in the following format: '2019-01-01' 2019-01-01\n",
      "Enter ending date of search in the following format: '2024-01-01' 2024-01-01\n",
      "Type \"YES\" for short sales YES\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ticker\n",
      "MSFt   -0.041691\n",
      "Name: weights, dtype: float64\n",
      "weight in passive portfolio: 1.041690508632659\n",
      "Sharpe W/Stocks: 1.3571779482986224\n",
      "Sharpe W/O Stocks: 1.329560524975003\n"
     ]
    }
   ],
   "source": [
    "rap = []\n",
    "USER_0 = True\n",
    "while USER_0 == True:\n",
    "    user_data = input(\"Type in Tickers to be Analyzed. Type 'DONE' when done.\")\n",
    "    if user_data == 'DONE':\n",
    "        USER_0 = False\n",
    "    else:\n",
    "        rap.append(user_data)\n",
    "\n",
    "start=input(\"Enter beginning date of search in the following format: '2019-01-01'\")\n",
    "end=input(\"Enter ending date of search in the following format: '2024-01-01'\")\n",
    "resample = 'MS'\n",
    "\n",
    "USER_4 = 0\n",
    "user_input = input('Type \"YES\" for short sales')\n",
    "if user_input == \"YES\":\n",
    "    USER_4 = 1\n",
    "else:\n",
    "    print('Short sales disabled.')\n",
    "\n",
    "rap_dict = {}\n",
    "rap_sigma = []\n",
    "rap_alpha = []\n",
    "rap_beta = []\n",
    "rap_CI_plus =[]\n",
    "rap_CI_minus = []\n",
    "rap_info = []\n",
    "rap_error = []\n",
    "\n",
    "snp_df = yf.download('^GSPC', start=start, end=end, progress=False).pct_change().dropna() -rf\n",
    "snp_df = snp_df.resample(resample).first()\n",
    "sigma_x = snp_df['Close'].std()\n",
    "x_bar = snp_df['Close'].mean()\n",
    "n_x = len(snp_df['Close'])\n",
    "\n",
    "\n",
    "for i in rap:\n",
    "    df_target = yf.download(i, start=start, end=end, progress=False).pct_change().dropna() -rf\n",
    "    df_target = df_target.resample(resample).first()\n",
    "    sigma_y = df_target['Close'].std()\n",
    "    y_bar = df_target['Close'].mean()\n",
    "    n_y = len(df_target['Close'])\n",
    "    pearson_xy = snp_df['Close'].corr(df_target['Close'])\n",
    "    r_square = pearson_xy**2\n",
    "    Beta_xy = pearson_xy*sigma_x/sigma_y \n",
    "    alpha_xy = y_bar - Beta_xy*x_bar\n",
    "    Sum_Squares_Error = sum((snp_df['Close'] - (alpha_xy + Beta_xy*df_target['Close']))**2)\n",
    "    Sum_Squares_Regression = sum(((alpha_xy + Beta_xy*df_target['Close']) - y_bar)**2)\n",
    "    Mean_Square_Error = Sum_Squares_Error/n_y-2\n",
    "    Mean_Square_Regression = Sum_Squares_Regression/1\n",
    "    F_Stat = Mean_Square_Regression/Mean_Square_Error\n",
    "    standard_error_estimate = Mean_Square_Error**.5\n",
    "\n",
    "    if stats.f.sf(F_Stat,1,n_y-2) <= .05:\n",
    "        beta_t = (Beta_xy-1)/(standard_error_estimate/sigma_x)\n",
    "        alpha_t = (alpha_xy - 0)/((1/n_x)+(x_bar**2/sigma_x**2))**.5\n",
    "    else:\n",
    "        significance = False\n",
    "\n",
    "    #Confidence Interval\n",
    "    Standard_Error_Forecast = standard_error_estimate*((1+1/n_x+(implied_erp-x_bar)**2/sigma_x**2)**.5)\n",
    "    Y_hat = alpha_xy +Beta_xy*implied_erp\n",
    "    t_value = t.ppf(1-.025,n_y-2)\n",
    "    CI_plus = Y_hat+t_value*Standard_Error_Forecast\n",
    "    CI_minus =Y_hat-t_value*Standard_Error_Forecast\n",
    "    info_ratio = alpha_xy/Sum_Squares_Error\n",
    "    \n",
    "    rap_sigma.append(sigma_x)\n",
    "    rap_alpha.append(alpha_xy)\n",
    "    rap_beta.append(Beta_xy)\n",
    "    rap_CI_plus.append(CI_plus)\n",
    "    rap_CI_minus.append(CI_minus)\n",
    "    rap_info.append(info_ratio)\n",
    "    rap_error.append(Sum_Squares_Error)\n",
    "    \n",
    "rap_dict = {'Ticker': rap, 'Stdev': rap_sigma, 'Alpha': rap_alpha, 'Beta' : rap_beta, 'CI \"-\"':\n",
    "            rap_CI_minus, 'CI \"+\"': rap_CI_plus, 'info_ratio':rap_info, 'Error': rap_error}    \n",
    "rap_df = pd.DataFrame(rap_dict)\n",
    "rap_df.set_index('Ticker', inplace=True)\n",
    "\n",
    "if USER_4 == 1:\n",
    "    rap_df['weights'] = rap_df['info_ratio']/rap_df['info_ratio'].sum()\n",
    "else: \n",
    "    rap_df['weights'] = rap_df['info_ratio']/rap_df['info_ratio'].sum().clip(min=0)\n",
    "    #rap_df['weights'] = rap_df['weights'].clip(lower=0)\n",
    "\n",
    "alpha_p = (rap_df['weights']*rap_df['Alpha']).sum()\n",
    "error_p = (rap_df['weights']**2 * rap_df['Error']).sum()\n",
    "\n",
    "initial_position = (alpha_p/error_p)/(implied_erp/(sigma_x**2))\n",
    "beta_active = (rap_df['weights']*rap_df['Beta']).sum()\n",
    "adj_position = initial_position/(1-(1-beta_active)*initial_position)\n",
    "idx_weight = 1-adj_position\n",
    "display = rap_df['weights']*adj_position\n",
    "RP_optimal = (idx_weight+beta_active*adj_position)*implied_erp+adj_position*alpha_p\n",
    "Variance_P = (idx_weight+beta_active*adj_position)**2*sigma_x**2+(adj_position**2*error_p)\n",
    "print(display)\n",
    "print(\"weight in passive portfolio:\", idx_weight)\n",
    "Sharpe_dowsed = RP_optimal/(Variance_P**.5)\n",
    "Sharpe_passive = implied_erp/sigma_x\n",
    "print(\"Sharpe W/Stocks:\", Sharpe_dowsed)\n",
    "print(\"Sharpe W/O Stocks:\", Sharpe_passive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab30d249-9fd9-403e-9d7a-9df689284643",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
